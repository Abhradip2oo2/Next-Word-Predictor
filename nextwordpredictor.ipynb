{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "jNNhhvrE1lr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "h9ww_bl0SRgU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK0Sle7Vz7cF"
      },
      "outputs": [],
      "source": [
        "df= \"\"\"What is the difference between supervised and unsupervised learning?\n",
        "Explain cross-validation.\n",
        "What is bias-variance tradeoff?\n",
        "Explain linear regression and its assumptions.\n",
        "How does regularization prevent overfitting?\n",
        "What are precision and recall?\n",
        "Explain the ROC curve and AUC.\n",
        "What is the purpose of clustering?\n",
        "Explain the k-means algorithm.\n",
        "Why is feature scaling important?\n",
        "What is one-hot encoding?\n",
        "Explain F1-score.\n",
        "How would you handle imbalanced datasets?\n",
        "What is a perceptron?\n",
        "Explain the architecture of a feedforward neural network.\n",
        "Explain the role of activation functions in neural networks.\n",
        "Compare and contrast sigmoid and ReLU activations.\n",
        "What are CNNs used for?\n",
        "Explain the concept of convolution.\n",
        "How do RNNs handle sequential data?\n",
        "What is the vanishing gradient problem?\n",
        "What is transfer learning?\n",
        "Explain the advantages of using pre-trained models.\n",
        "Exploratory Data Analysis (EDA):\n",
        "What is EDA, and why is it important?\n",
        "How do you handle missing data?\n",
        "What are the methods for feature selection?\n",
        "Explain the curse of dimensionality.\n",
        "How do you deploy a machine learning model?\n",
        "What is Docker, and how is it used in model deployment?\n",
        "What is Apache Spark, and how is it used in data processing?\n",
        "Explain the concept of MapReduce.\n",
        "Write a SQL query to find the second-highest salary in a table.\n",
        "What is normalization in databases?\n",
        "What is algorithmic bias?\n",
        "How do you ensure a model is fair?\n",
        "Explain bagging and boosting.\n",
        "What is the random forest algorithm?\n",
        "How do you handle time series data in machine learning?\n",
        "Explain autoregression.\n",
        "What are n-grams in NLP?\n",
        "Explain the concept of word embeddings.\n",
        "Explain stochastic gradient descent.\n",
        "What is the Adam optimizer?\n",
        "How does a decision tree handle categorical variables?\n",
        "Explain the concept of entropy in the context of decision trees.\n",
        "How does an SVM handle non-linearly separable data?\n",
        "What is the kernel trick in SVMs?\n",
        "Compare K-means clustering and hierarchical clustering.\n",
        "How do you determine the optimal number of clusters in K-means?\n",
        "What is L1 regularization, and how does it differ from L2 regularization?\n",
        "How does regularization affect the bias-variance tradeoff?\n",
        "Explain the steps of the gradient descent algorithm.\n",
        "What is the learning rate, and how does it impact the convergence of gradient descent?\n",
        "What is batch normalization, and why is it used in neural networks?\n",
        "Explain how batch normalization helps with training deep networks.\n",
        "How do RNNs handle the vanishing gradient problem?\n",
        "Explain the concept of long short-term memory (LSTM) cells.\n",
        "What is an autoencoder?\n",
        "How can autoencoders be used for dimensionality reduction?\n",
        "Explain fine-tuning in transfer learning.\n",
        "What are the challenges of transfer learning?\n",
        "What is the basic idea behind GANs?\n",
        "Explain the roles of the generator and discriminator in a GAN.\n",
        "Why is model interpretability important?\n",
        "How can you explain a complex machine learning model to a non-technical stakeholder?\n",
        "Explain the concepts of time complexity and space complexity.\n",
        "How do they relate to algorithm efficiency?\n",
        "What is A/B testing, and how is it used in data science?\n",
        "Explain the difference between statistical significance and practical significance in the context of A/B testing.\n",
        "Compare PCA (Principal Component Analysis) and t-SNE (t-distributed Stochastic Neighbor Embedding).\n",
        "When would you choose one over the other for dimensionality reduction?\n",
        "What are the ethical considerations in handling sensitive data?\n",
        "How can biases be introduced into a machine learning model, and how would you address them?\n",
        "Explain the basic components of a reinforcement learning system.\n",
        "What is the difference between supervised learning and reinforcement learning?\n",
        "Why is proper initialization important in neural networks?\n",
        "Explain the difference between zero initialization, random initialization, and He initialization.\n",
        "How do outliers impact machine learning models?\n",
        "What techniques can be used to detect and handle outliers?\n",
        "Explain the logistic regression algorithm.\n",
        "How does logistic regression handle multi-class classification?\n",
        "What is collinearity, and why is it a problem in linear regression?\n",
        "How can you detect and address collinearity in a dataset?\n",
        "Tell me about yourself.\n",
        "Why are you interested in the field of machine learning/data science?\n",
        "What projects have you worked on during your studies or personal projects?\n",
        "What programming languages are you comfortable with?\n",
        "Explain the difference between supervised and unsupervised learning.\n",
        "What is cross-validation, and why is it important?\n",
        "Describe a machine learning model you've implemented.\n",
        "What is overfitting, and how can it be prevented?\n",
        "What is the bias-variance tradeoff?\n",
        "How do you handle missing data in a dataset?\n",
        "Explain the concept of normalization and why it is important.\n",
        "What is the difference between a list and a tuple in Python?\n",
        "How would you clean and preprocess a dataset before using it in a machine learning model?\n",
        "What is the basic structure of a neural network?\n",
        "Explain the purpose of activation functions in neural networks.\n",
        "What is backpropagation in the context of neural networks?\n",
        "How do convolutional neural networks (CNNs) differ from traditional neural networks?\n",
        "Given a dataset, how would you approach exploring and understanding it?\n",
        "If you had a dataset with a class imbalance, how would you handle it?\n",
        "How would you choose between different machine learning models for a specific task?\n",
        "Explain a complex concept from your studies or projects in a simple way.\n",
        "How do you handle tight deadlines and multiple projects?\n",
        "Describe a challenging problem you faced in a project and how you solved it.\n",
        "How do you stay updated with the latest developments in machine learning and data science?\n",
        "How do you handle situations when your code or model doesn't work as expected?\n",
        "Why do you want to work for this company?\n",
        "What recent trends or advancements in machine learning/data science interest you the most?\n",
        "Can you name some influential figures or key research papers in the field?\n",
        "Write code to implement linear regression from scratch.\n",
        "Explain the steps of a machine learning project from problem definition to deployment.\n",
        "Given a dataset, perform exploratory data analysis and highlight important insights.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenising\n",
        "tokenizer.fit_on_texts([df])"
      ],
      "metadata": {
        "id": "cym0xw402Dan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG10sSKL2ORY",
        "outputId": "81742047-f67e-4146-e8dc-22ba4b66f462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'is': 2,\n",
              " 'what': 3,\n",
              " 'how': 4,\n",
              " 'and': 5,\n",
              " 'a': 6,\n",
              " 'explain': 7,\n",
              " 'in': 8,\n",
              " 'you': 9,\n",
              " 'of': 10,\n",
              " 'learning': 11,\n",
              " 'do': 12,\n",
              " 'it': 13,\n",
              " 'handle': 14,\n",
              " 'data': 15,\n",
              " 'machine': 16,\n",
              " 'why': 17,\n",
              " 'neural': 18,\n",
              " 'model': 19,\n",
              " 'are': 20,\n",
              " 'networks': 21,\n",
              " 'between': 22,\n",
              " 'does': 23,\n",
              " 'important': 24,\n",
              " 'would': 25,\n",
              " 'used': 26,\n",
              " 'concept': 27,\n",
              " 'to': 28,\n",
              " 'can': 29,\n",
              " 'difference': 30,\n",
              " 'for': 31,\n",
              " 'dataset': 32,\n",
              " 'regression': 33,\n",
              " 'algorithm': 34,\n",
              " 'gradient': 35,\n",
              " 'problem': 36,\n",
              " 'from': 37,\n",
              " 'or': 38,\n",
              " 'bias': 39,\n",
              " 'regularization': 40,\n",
              " 'normalization': 41,\n",
              " 'with': 42,\n",
              " 'be': 43,\n",
              " 'science': 44,\n",
              " 'initialization': 45,\n",
              " 'projects': 46,\n",
              " 'supervised': 47,\n",
              " 'variance': 48,\n",
              " 'tradeoff': 49,\n",
              " 'linear': 50,\n",
              " 'clustering': 51,\n",
              " 'k': 52,\n",
              " 'means': 53,\n",
              " 'compare': 54,\n",
              " 'transfer': 55,\n",
              " 'models': 56,\n",
              " 'analysis': 57,\n",
              " 'dimensionality': 58,\n",
              " 'descent': 59,\n",
              " 'context': 60,\n",
              " 'basic': 61,\n",
              " 'your': 62,\n",
              " 'unsupervised': 63,\n",
              " 'cross': 64,\n",
              " 'validation': 65,\n",
              " 'overfitting': 66,\n",
              " 'purpose': 67,\n",
              " 'feature': 68,\n",
              " 'one': 69,\n",
              " 'network': 70,\n",
              " 'activation': 71,\n",
              " 'functions': 72,\n",
              " 'cnns': 73,\n",
              " 'rnns': 74,\n",
              " 'vanishing': 75,\n",
              " 'using': 76,\n",
              " 'exploratory': 77,\n",
              " 'eda': 78,\n",
              " 'missing': 79,\n",
              " 'deployment': 80,\n",
              " 'write': 81,\n",
              " 'random': 82,\n",
              " 'time': 83,\n",
              " 'stochastic': 84,\n",
              " 'decision': 85,\n",
              " 'an': 86,\n",
              " 'non': 87,\n",
              " 'differ': 88,\n",
              " 'steps': 89,\n",
              " 'impact': 90,\n",
              " 'batch': 91,\n",
              " 'reduction': 92,\n",
              " 'complex': 93,\n",
              " 'complexity': 94,\n",
              " 'b': 95,\n",
              " 'testing': 96,\n",
              " 'significance': 97,\n",
              " 't': 98,\n",
              " 'when': 99,\n",
              " 'choose': 100,\n",
              " 'address': 101,\n",
              " 'reinforcement': 102,\n",
              " 'outliers': 103,\n",
              " 'detect': 104,\n",
              " 'logistic': 105,\n",
              " 'class': 106,\n",
              " 'collinearity': 107,\n",
              " 'field': 108,\n",
              " 'studies': 109,\n",
              " 'describe': 110,\n",
              " 'given': 111,\n",
              " 'project': 112,\n",
              " 'code': 113,\n",
              " 'work': 114,\n",
              " 'its': 115,\n",
              " 'assumptions': 116,\n",
              " 'prevent': 117,\n",
              " 'precision': 118,\n",
              " 'recall': 119,\n",
              " 'roc': 120,\n",
              " 'curve': 121,\n",
              " 'auc': 122,\n",
              " 'scaling': 123,\n",
              " 'hot': 124,\n",
              " 'encoding': 125,\n",
              " 'f1': 126,\n",
              " 'score': 127,\n",
              " 'imbalanced': 128,\n",
              " 'datasets': 129,\n",
              " 'perceptron': 130,\n",
              " 'architecture': 131,\n",
              " 'feedforward': 132,\n",
              " 'role': 133,\n",
              " 'contrast': 134,\n",
              " 'sigmoid': 135,\n",
              " 'relu': 136,\n",
              " 'activations': 137,\n",
              " 'convolution': 138,\n",
              " 'sequential': 139,\n",
              " 'advantages': 140,\n",
              " 'pre': 141,\n",
              " 'trained': 142,\n",
              " 'methods': 143,\n",
              " 'selection': 144,\n",
              " 'curse': 145,\n",
              " 'deploy': 146,\n",
              " 'docker': 147,\n",
              " 'apache': 148,\n",
              " 'spark': 149,\n",
              " 'processing': 150,\n",
              " 'mapreduce': 151,\n",
              " 'sql': 152,\n",
              " 'query': 153,\n",
              " 'find': 154,\n",
              " 'second': 155,\n",
              " 'highest': 156,\n",
              " 'salary': 157,\n",
              " 'table': 158,\n",
              " 'databases': 159,\n",
              " 'algorithmic': 160,\n",
              " 'ensure': 161,\n",
              " 'fair': 162,\n",
              " 'bagging': 163,\n",
              " 'boosting': 164,\n",
              " 'forest': 165,\n",
              " 'series': 166,\n",
              " 'autoregression': 167,\n",
              " 'n': 168,\n",
              " 'grams': 169,\n",
              " 'nlp': 170,\n",
              " 'word': 171,\n",
              " 'embeddings': 172,\n",
              " 'adam': 173,\n",
              " 'optimizer': 174,\n",
              " 'tree': 175,\n",
              " 'categorical': 176,\n",
              " 'variables': 177,\n",
              " 'entropy': 178,\n",
              " 'trees': 179,\n",
              " 'svm': 180,\n",
              " 'linearly': 181,\n",
              " 'separable': 182,\n",
              " 'kernel': 183,\n",
              " 'trick': 184,\n",
              " 'svms': 185,\n",
              " 'hierarchical': 186,\n",
              " 'determine': 187,\n",
              " 'optimal': 188,\n",
              " 'number': 189,\n",
              " 'clusters': 190,\n",
              " 'l1': 191,\n",
              " 'l2': 192,\n",
              " 'affect': 193,\n",
              " 'rate': 194,\n",
              " 'convergence': 195,\n",
              " 'helps': 196,\n",
              " 'training': 197,\n",
              " 'deep': 198,\n",
              " 'long': 199,\n",
              " 'short': 200,\n",
              " 'term': 201,\n",
              " 'memory': 202,\n",
              " 'lstm': 203,\n",
              " 'cells': 204,\n",
              " 'autoencoder': 205,\n",
              " 'autoencoders': 206,\n",
              " 'fine': 207,\n",
              " 'tuning': 208,\n",
              " 'challenges': 209,\n",
              " 'idea': 210,\n",
              " 'behind': 211,\n",
              " 'gans': 212,\n",
              " 'roles': 213,\n",
              " 'generator': 214,\n",
              " 'discriminator': 215,\n",
              " 'gan': 216,\n",
              " 'interpretability': 217,\n",
              " 'technical': 218,\n",
              " 'stakeholder': 219,\n",
              " 'concepts': 220,\n",
              " 'space': 221,\n",
              " 'they': 222,\n",
              " 'relate': 223,\n",
              " 'efficiency': 224,\n",
              " 'statistical': 225,\n",
              " 'practical': 226,\n",
              " 'pca': 227,\n",
              " 'principal': 228,\n",
              " 'component': 229,\n",
              " 'sne': 230,\n",
              " 'distributed': 231,\n",
              " 'neighbor': 232,\n",
              " 'embedding': 233,\n",
              " 'over': 234,\n",
              " 'other': 235,\n",
              " 'ethical': 236,\n",
              " 'considerations': 237,\n",
              " 'handling': 238,\n",
              " 'sensitive': 239,\n",
              " 'biases': 240,\n",
              " 'introduced': 241,\n",
              " 'into': 242,\n",
              " 'them': 243,\n",
              " 'components': 244,\n",
              " 'system': 245,\n",
              " 'proper': 246,\n",
              " 'zero': 247,\n",
              " 'he': 248,\n",
              " 'techniques': 249,\n",
              " 'multi': 250,\n",
              " 'classification': 251,\n",
              " 'tell': 252,\n",
              " 'me': 253,\n",
              " 'about': 254,\n",
              " 'yourself': 255,\n",
              " 'interested': 256,\n",
              " 'have': 257,\n",
              " 'worked': 258,\n",
              " 'on': 259,\n",
              " 'during': 260,\n",
              " 'personal': 261,\n",
              " 'programming': 262,\n",
              " 'languages': 263,\n",
              " 'comfortable': 264,\n",
              " \"you've\": 265,\n",
              " 'implemented': 266,\n",
              " 'prevented': 267,\n",
              " 'list': 268,\n",
              " 'tuple': 269,\n",
              " 'python': 270,\n",
              " 'clean': 271,\n",
              " 'preprocess': 272,\n",
              " 'before': 273,\n",
              " 'structure': 274,\n",
              " 'backpropagation': 275,\n",
              " 'convolutional': 276,\n",
              " 'traditional': 277,\n",
              " 'approach': 278,\n",
              " 'exploring': 279,\n",
              " 'understanding': 280,\n",
              " 'if': 281,\n",
              " 'had': 282,\n",
              " 'imbalance': 283,\n",
              " 'different': 284,\n",
              " 'specific': 285,\n",
              " 'task': 286,\n",
              " 'simple': 287,\n",
              " 'way': 288,\n",
              " 'tight': 289,\n",
              " 'deadlines': 290,\n",
              " 'multiple': 291,\n",
              " 'challenging': 292,\n",
              " 'faced': 293,\n",
              " 'solved': 294,\n",
              " 'stay': 295,\n",
              " 'updated': 296,\n",
              " 'latest': 297,\n",
              " 'developments': 298,\n",
              " 'situations': 299,\n",
              " \"doesn't\": 300,\n",
              " 'as': 301,\n",
              " 'expected': 302,\n",
              " 'want': 303,\n",
              " 'this': 304,\n",
              " 'company': 305,\n",
              " 'recent': 306,\n",
              " 'trends': 307,\n",
              " 'advancements': 308,\n",
              " 'interest': 309,\n",
              " 'most': 310,\n",
              " 'name': 311,\n",
              " 'some': 312,\n",
              " 'influential': 313,\n",
              " 'figures': 314,\n",
              " 'key': 315,\n",
              " 'research': 316,\n",
              " 'papers': 317,\n",
              " 'implement': 318,\n",
              " 'scratch': 319,\n",
              " 'definition': 320,\n",
              " 'perform': 321,\n",
              " 'highlight': 322,\n",
              " 'insights': 323}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in df.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0] #converting rows of words(sentences) to row of numbers\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1]) #n-gram"
      ],
      "metadata": {
        "id": "5EmHx9-b3Nkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoVFz2CE4--A",
        "outputId": "7f6adb26-64f3-42ed-af58-fa86958e51ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 30],\n",
              " [3, 2, 1, 30, 22],\n",
              " [3, 2, 1, 30, 22, 47],\n",
              " [3, 2, 1, 30, 22, 47, 5],\n",
              " [3, 2, 1, 30, 22, 47, 5, 63],\n",
              " [3, 2, 1, 30, 22, 47, 5, 63, 11],\n",
              " [7, 64],\n",
              " [7, 64, 65],\n",
              " [3, 2],\n",
              " [3, 2, 39],\n",
              " [3, 2, 39, 48],\n",
              " [3, 2, 39, 48, 49],\n",
              " [7, 50],\n",
              " [7, 50, 33],\n",
              " [7, 50, 33, 5],\n",
              " [7, 50, 33, 5, 115],\n",
              " [7, 50, 33, 5, 115, 116],\n",
              " [4, 23],\n",
              " [4, 23, 40],\n",
              " [4, 23, 40, 117],\n",
              " [4, 23, 40, 117, 66],\n",
              " [3, 20],\n",
              " [3, 20, 118],\n",
              " [3, 20, 118, 5],\n",
              " [3, 20, 118, 5, 119],\n",
              " [7, 1],\n",
              " [7, 1, 120],\n",
              " [7, 1, 120, 121],\n",
              " [7, 1, 120, 121, 5],\n",
              " [7, 1, 120, 121, 5, 122],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 67],\n",
              " [3, 2, 1, 67, 10],\n",
              " [3, 2, 1, 67, 10, 51],\n",
              " [7, 1],\n",
              " [7, 1, 52],\n",
              " [7, 1, 52, 53],\n",
              " [7, 1, 52, 53, 34],\n",
              " [17, 2],\n",
              " [17, 2, 68],\n",
              " [17, 2, 68, 123],\n",
              " [17, 2, 68, 123, 24],\n",
              " [3, 2],\n",
              " [3, 2, 69],\n",
              " [3, 2, 69, 124],\n",
              " [3, 2, 69, 124, 125],\n",
              " [7, 126],\n",
              " [7, 126, 127],\n",
              " [4, 25],\n",
              " [4, 25, 9],\n",
              " [4, 25, 9, 14],\n",
              " [4, 25, 9, 14, 128],\n",
              " [4, 25, 9, 14, 128, 129],\n",
              " [3, 2],\n",
              " [3, 2, 6],\n",
              " [3, 2, 6, 130],\n",
              " [7, 1],\n",
              " [7, 1, 131],\n",
              " [7, 1, 131, 10],\n",
              " [7, 1, 131, 10, 6],\n",
              " [7, 1, 131, 10, 6, 132],\n",
              " [7, 1, 131, 10, 6, 132, 18],\n",
              " [7, 1, 131, 10, 6, 132, 18, 70],\n",
              " [7, 1],\n",
              " [7, 1, 133],\n",
              " [7, 1, 133, 10],\n",
              " [7, 1, 133, 10, 71],\n",
              " [7, 1, 133, 10, 71, 72],\n",
              " [7, 1, 133, 10, 71, 72, 8],\n",
              " [7, 1, 133, 10, 71, 72, 8, 18],\n",
              " [7, 1, 133, 10, 71, 72, 8, 18, 21],\n",
              " [54, 5],\n",
              " [54, 5, 134],\n",
              " [54, 5, 134, 135],\n",
              " [54, 5, 134, 135, 5],\n",
              " [54, 5, 134, 135, 5, 136],\n",
              " [54, 5, 134, 135, 5, 136, 137],\n",
              " [3, 20],\n",
              " [3, 20, 73],\n",
              " [3, 20, 73, 26],\n",
              " [3, 20, 73, 26, 31],\n",
              " [7, 1],\n",
              " [7, 1, 27],\n",
              " [7, 1, 27, 10],\n",
              " [7, 1, 27, 10, 138],\n",
              " [4, 12],\n",
              " [4, 12, 74],\n",
              " [4, 12, 74, 14],\n",
              " [4, 12, 74, 14, 139],\n",
              " [4, 12, 74, 14, 139, 15],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 75],\n",
              " [3, 2, 1, 75, 35],\n",
              " [3, 2, 1, 75, 35, 36],\n",
              " [3, 2],\n",
              " [3, 2, 55],\n",
              " [3, 2, 55, 11],\n",
              " [7, 1],\n",
              " [7, 1, 140],\n",
              " [7, 1, 140, 10],\n",
              " [7, 1, 140, 10, 76],\n",
              " [7, 1, 140, 10, 76, 141],\n",
              " [7, 1, 140, 10, 76, 141, 142],\n",
              " [7, 1, 140, 10, 76, 141, 142, 56],\n",
              " [77, 15],\n",
              " [77, 15, 57],\n",
              " [77, 15, 57, 78],\n",
              " [3, 2],\n",
              " [3, 2, 78],\n",
              " [3, 2, 78, 5],\n",
              " [3, 2, 78, 5, 17],\n",
              " [3, 2, 78, 5, 17, 2],\n",
              " [3, 2, 78, 5, 17, 2, 13],\n",
              " [3, 2, 78, 5, 17, 2, 13, 24],\n",
              " [4, 12],\n",
              " [4, 12, 9],\n",
              " [4, 12, 9, 14],\n",
              " [4, 12, 9, 14, 79],\n",
              " [4, 12, 9, 14, 79, 15],\n",
              " [3, 20],\n",
              " [3, 20, 1],\n",
              " [3, 20, 1, 143],\n",
              " [3, 20, 1, 143, 31],\n",
              " [3, 20, 1, 143, 31, 68],\n",
              " [3, 20, 1, 143, 31, 68, 144],\n",
              " [7, 1],\n",
              " [7, 1, 145],\n",
              " [7, 1, 145, 10],\n",
              " [7, 1, 145, 10, 58],\n",
              " [4, 12],\n",
              " [4, 12, 9],\n",
              " [4, 12, 9, 146],\n",
              " [4, 12, 9, 146, 6],\n",
              " [4, 12, 9, 146, 6, 16],\n",
              " [4, 12, 9, 146, 6, 16, 11],\n",
              " [4, 12, 9, 146, 6, 16, 11, 19],\n",
              " [3, 2],\n",
              " [3, 2, 147],\n",
              " [3, 2, 147, 5],\n",
              " [3, 2, 147, 5, 4],\n",
              " [3, 2, 147, 5, 4, 2],\n",
              " [3, 2, 147, 5, 4, 2, 13],\n",
              " [3, 2, 147, 5, 4, 2, 13, 26],\n",
              " [3, 2, 147, 5, 4, 2, 13, 26, 8],\n",
              " [3, 2, 147, 5, 4, 2, 13, 26, 8, 19],\n",
              " [3, 2, 147, 5, 4, 2, 13, 26, 8, 19, 80],\n",
              " [3, 2],\n",
              " [3, 2, 148],\n",
              " [3, 2, 148, 149],\n",
              " [3, 2, 148, 149, 5],\n",
              " [3, 2, 148, 149, 5, 4],\n",
              " [3, 2, 148, 149, 5, 4, 2],\n",
              " [3, 2, 148, 149, 5, 4, 2, 13],\n",
              " [3, 2, 148, 149, 5, 4, 2, 13, 26],\n",
              " [3, 2, 148, 149, 5, 4, 2, 13, 26, 8],\n",
              " [3, 2, 148, 149, 5, 4, 2, 13, 26, 8, 15],\n",
              " [3, 2, 148, 149, 5, 4, 2, 13, 26, 8, 15, 150],\n",
              " [7, 1],\n",
              " [7, 1, 27],\n",
              " [7, 1, 27, 10],\n",
              " [7, 1, 27, 10, 151],\n",
              " [81, 6],\n",
              " [81, 6, 152],\n",
              " [81, 6, 152, 153],\n",
              " [81, 6, 152, 153, 28],\n",
              " [81, 6, 152, 153, 28, 154],\n",
              " [81, 6, 152, 153, 28, 154, 1],\n",
              " [81, 6, 152, 153, 28, 154, 1, 155],\n",
              " [81, 6, 152, 153, 28, 154, 1, 155, 156],\n",
              " [81, 6, 152, 153, 28, 154, 1, 155, 156, 157],\n",
              " [81, 6, 152, 153, 28, 154, 1, 155, 156, 157, 8],\n",
              " [81, 6, 152, 153, 28, 154, 1, 155, 156, 157, 8, 6],\n",
              " [81, 6, 152, 153, 28, 154, 1, 155, 156, 157, 8, 6, 158],\n",
              " [3, 2],\n",
              " [3, 2, 41],\n",
              " [3, 2, 41, 8],\n",
              " [3, 2, 41, 8, 159],\n",
              " [3, 2],\n",
              " [3, 2, 160],\n",
              " [3, 2, 160, 39],\n",
              " [4, 12],\n",
              " [4, 12, 9],\n",
              " [4, 12, 9, 161],\n",
              " [4, 12, 9, 161, 6],\n",
              " [4, 12, 9, 161, 6, 19],\n",
              " [4, 12, 9, 161, 6, 19, 2],\n",
              " [4, 12, 9, 161, 6, 19, 2, 162],\n",
              " [7, 163],\n",
              " [7, 163, 5],\n",
              " [7, 163, 5, 164],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 82],\n",
              " [3, 2, 1, 82, 165],\n",
              " [3, 2, 1, 82, 165, 34],\n",
              " [4, 12],\n",
              " [4, 12, 9],\n",
              " [4, 12, 9, 14],\n",
              " [4, 12, 9, 14, 83],\n",
              " [4, 12, 9, 14, 83, 166],\n",
              " [4, 12, 9, 14, 83, 166, 15],\n",
              " [4, 12, 9, 14, 83, 166, 15, 8],\n",
              " [4, 12, 9, 14, 83, 166, 15, 8, 16],\n",
              " [4, 12, 9, 14, 83, 166, 15, 8, 16, 11],\n",
              " [7, 167],\n",
              " [3, 20],\n",
              " [3, 20, 168],\n",
              " [3, 20, 168, 169],\n",
              " [3, 20, 168, 169, 8],\n",
              " [3, 20, 168, 169, 8, 170],\n",
              " [7, 1],\n",
              " [7, 1, 27],\n",
              " [7, 1, 27, 10],\n",
              " [7, 1, 27, 10, 171],\n",
              " [7, 1, 27, 10, 171, 172],\n",
              " [7, 84],\n",
              " [7, 84, 35],\n",
              " [7, 84, 35, 59],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 173],\n",
              " [3, 2, 1, 173, 174],\n",
              " [4, 23],\n",
              " [4, 23, 6],\n",
              " [4, 23, 6, 85],\n",
              " [4, 23, 6, 85, 175],\n",
              " [4, 23, 6, 85, 175, 14],\n",
              " [4, 23, 6, 85, 175, 14, 176],\n",
              " [4, 23, 6, 85, 175, 14, 176, 177],\n",
              " [7, 1],\n",
              " [7, 1, 27],\n",
              " [7, 1, 27, 10],\n",
              " [7, 1, 27, 10, 178],\n",
              " [7, 1, 27, 10, 178, 8],\n",
              " [7, 1, 27, 10, 178, 8, 1],\n",
              " [7, 1, 27, 10, 178, 8, 1, 60],\n",
              " [7, 1, 27, 10, 178, 8, 1, 60, 10],\n",
              " [7, 1, 27, 10, 178, 8, 1, 60, 10, 85],\n",
              " [7, 1, 27, 10, 178, 8, 1, 60, 10, 85, 179],\n",
              " [4, 23],\n",
              " [4, 23, 86],\n",
              " [4, 23, 86, 180],\n",
              " [4, 23, 86, 180, 14],\n",
              " [4, 23, 86, 180, 14, 87],\n",
              " [4, 23, 86, 180, 14, 87, 181],\n",
              " [4, 23, 86, 180, 14, 87, 181, 182],\n",
              " [4, 23, 86, 180, 14, 87, 181, 182, 15],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 183],\n",
              " [3, 2, 1, 183, 184],\n",
              " [3, 2, 1, 183, 184, 8],\n",
              " [3, 2, 1, 183, 184, 8, 185],\n",
              " [54, 52],\n",
              " [54, 52, 53],\n",
              " [54, 52, 53, 51],\n",
              " [54, 52, 53, 51, 5],\n",
              " [54, 52, 53, 51, 5, 186],\n",
              " [54, 52, 53, 51, 5, 186, 51],\n",
              " [4, 12],\n",
              " [4, 12, 9],\n",
              " [4, 12, 9, 187],\n",
              " [4, 12, 9, 187, 1],\n",
              " [4, 12, 9, 187, 1, 188],\n",
              " [4, 12, 9, 187, 1, 188, 189],\n",
              " [4, 12, 9, 187, 1, 188, 189, 10],\n",
              " [4, 12, 9, 187, 1, 188, 189, 10, 190],\n",
              " [4, 12, 9, 187, 1, 188, 189, 10, 190, 8],\n",
              " [4, 12, 9, 187, 1, 188, 189, 10, 190, 8, 52],\n",
              " [4, 12, 9, 187, 1, 188, 189, 10, 190, 8, 52, 53],\n",
              " [3, 2],\n",
              " [3, 2, 191],\n",
              " [3, 2, 191, 40],\n",
              " [3, 2, 191, 40, 5],\n",
              " [3, 2, 191, 40, 5, 4],\n",
              " [3, 2, 191, 40, 5, 4, 23],\n",
              " [3, 2, 191, 40, 5, 4, 23, 13],\n",
              " [3, 2, 191, 40, 5, 4, 23, 13, 88],\n",
              " [3, 2, 191, 40, 5, 4, 23, 13, 88, 37],\n",
              " [3, 2, 191, 40, 5, 4, 23, 13, 88, 37, 192],\n",
              " [3, 2, 191, 40, 5, 4, 23, 13, 88, 37, 192, 40],\n",
              " [4, 23],\n",
              " [4, 23, 40],\n",
              " [4, 23, 40, 193],\n",
              " [4, 23, 40, 193, 1],\n",
              " [4, 23, 40, 193, 1, 39],\n",
              " [4, 23, 40, 193, 1, 39, 48],\n",
              " [4, 23, 40, 193, 1, 39, 48, 49],\n",
              " [7, 1],\n",
              " [7, 1, 89],\n",
              " [7, 1, 89, 10],\n",
              " [7, 1, 89, 10, 1],\n",
              " [7, 1, 89, 10, 1, 35],\n",
              " [7, 1, 89, 10, 1, 35, 59],\n",
              " [7, 1, 89, 10, 1, 35, 59, 34],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 11],\n",
              " [3, 2, 1, 11, 194],\n",
              " [3, 2, 1, 11, 194, 5],\n",
              " [3, 2, 1, 11, 194, 5, 4],\n",
              " [3, 2, 1, 11, 194, 5, 4, 23],\n",
              " [3, 2, 1, 11, 194, 5, 4, 23, 13],\n",
              " [3, 2, 1, 11, 194, 5, 4, 23, 13, 90],\n",
              " [3, 2, 1, 11, 194, 5, 4, 23, 13, 90, 1],\n",
              " [3, 2, 1, 11, 194, 5, 4, 23, 13, 90, 1, 195],\n",
              " [3, 2, 1, 11, 194, 5, 4, 23, 13, 90, 1, 195, 10],\n",
              " [3, 2, 1, 11, 194, 5, 4, 23, 13, 90, 1, 195, 10, 35],\n",
              " [3, 2, 1, 11, 194, 5, 4, 23, 13, 90, 1, 195, 10, 35, 59],\n",
              " [3, 2],\n",
              " [3, 2, 91],\n",
              " [3, 2, 91, 41],\n",
              " [3, 2, 91, 41, 5],\n",
              " [3, 2, 91, 41, 5, 17],\n",
              " [3, 2, 91, 41, 5, 17, 2],\n",
              " [3, 2, 91, 41, 5, 17, 2, 13],\n",
              " [3, 2, 91, 41, 5, 17, 2, 13, 26],\n",
              " [3, 2, 91, 41, 5, 17, 2, 13, 26, 8],\n",
              " [3, 2, 91, 41, 5, 17, 2, 13, 26, 8, 18],\n",
              " [3, 2, 91, 41, 5, 17, 2, 13, 26, 8, 18, 21],\n",
              " [7, 4],\n",
              " [7, 4, 91],\n",
              " [7, 4, 91, 41],\n",
              " [7, 4, 91, 41, 196],\n",
              " [7, 4, 91, 41, 196, 42],\n",
              " [7, 4, 91, 41, 196, 42, 197],\n",
              " [7, 4, 91, 41, 196, 42, 197, 198],\n",
              " [7, 4, 91, 41, 196, 42, 197, 198, 21],\n",
              " [4, 12],\n",
              " [4, 12, 74],\n",
              " [4, 12, 74, 14],\n",
              " [4, 12, 74, 14, 1],\n",
              " [4, 12, 74, 14, 1, 75],\n",
              " [4, 12, 74, 14, 1, 75, 35],\n",
              " [4, 12, 74, 14, 1, 75, 35, 36],\n",
              " [7, 1],\n",
              " [7, 1, 27],\n",
              " [7, 1, 27, 10],\n",
              " [7, 1, 27, 10, 199],\n",
              " [7, 1, 27, 10, 199, 200],\n",
              " [7, 1, 27, 10, 199, 200, 201],\n",
              " [7, 1, 27, 10, 199, 200, 201, 202],\n",
              " [7, 1, 27, 10, 199, 200, 201, 202, 203],\n",
              " [7, 1, 27, 10, 199, 200, 201, 202, 203, 204],\n",
              " [3, 2],\n",
              " [3, 2, 86],\n",
              " [3, 2, 86, 205],\n",
              " [4, 29],\n",
              " [4, 29, 206],\n",
              " [4, 29, 206, 43],\n",
              " [4, 29, 206, 43, 26],\n",
              " [4, 29, 206, 43, 26, 31],\n",
              " [4, 29, 206, 43, 26, 31, 58],\n",
              " [4, 29, 206, 43, 26, 31, 58, 92],\n",
              " [7, 207],\n",
              " [7, 207, 208],\n",
              " [7, 207, 208, 8],\n",
              " [7, 207, 208, 8, 55],\n",
              " [7, 207, 208, 8, 55, 11],\n",
              " [3, 20],\n",
              " [3, 20, 1],\n",
              " [3, 20, 1, 209],\n",
              " [3, 20, 1, 209, 10],\n",
              " [3, 20, 1, 209, 10, 55],\n",
              " [3, 20, 1, 209, 10, 55, 11],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 61],\n",
              " [3, 2, 1, 61, 210],\n",
              " [3, 2, 1, 61, 210, 211],\n",
              " [3, 2, 1, 61, 210, 211, 212],\n",
              " [7, 1],\n",
              " [7, 1, 213],\n",
              " [7, 1, 213, 10],\n",
              " [7, 1, 213, 10, 1],\n",
              " [7, 1, 213, 10, 1, 214],\n",
              " [7, 1, 213, 10, 1, 214, 5],\n",
              " [7, 1, 213, 10, 1, 214, 5, 215],\n",
              " [7, 1, 213, 10, 1, 214, 5, 215, 8],\n",
              " [7, 1, 213, 10, 1, 214, 5, 215, 8, 6],\n",
              " [7, 1, 213, 10, 1, 214, 5, 215, 8, 6, 216],\n",
              " [17, 2],\n",
              " [17, 2, 19],\n",
              " [17, 2, 19, 217],\n",
              " [17, 2, 19, 217, 24],\n",
              " [4, 29],\n",
              " [4, 29, 9],\n",
              " [4, 29, 9, 7],\n",
              " [4, 29, 9, 7, 6],\n",
              " [4, 29, 9, 7, 6, 93],\n",
              " [4, 29, 9, 7, 6, 93, 16],\n",
              " [4, 29, 9, 7, 6, 93, 16, 11],\n",
              " [4, 29, 9, 7, 6, 93, 16, 11, 19],\n",
              " [4, 29, 9, 7, 6, 93, 16, 11, 19, 28],\n",
              " [4, 29, 9, 7, 6, 93, 16, 11, 19, 28, 6],\n",
              " [4, 29, 9, 7, 6, 93, 16, 11, 19, 28, 6, 87],\n",
              " [4, 29, 9, 7, 6, 93, 16, 11, 19, 28, 6, 87, 218],\n",
              " [4, 29, 9, 7, 6, 93, 16, 11, 19, 28, 6, 87, 218, 219],\n",
              " [7, 1],\n",
              " [7, 1, 220],\n",
              " [7, 1, 220, 10],\n",
              " [7, 1, 220, 10, 83],\n",
              " [7, 1, 220, 10, 83, 94],\n",
              " [7, 1, 220, 10, 83, 94, 5],\n",
              " [7, 1, 220, 10, 83, 94, 5, 221],\n",
              " [7, 1, 220, 10, 83, 94, 5, 221, 94],\n",
              " [4, 12],\n",
              " [4, 12, 222],\n",
              " [4, 12, 222, 223],\n",
              " [4, 12, 222, 223, 28],\n",
              " [4, 12, 222, 223, 28, 34],\n",
              " [4, 12, 222, 223, 28, 34, 224],\n",
              " [3, 2],\n",
              " [3, 2, 6],\n",
              " [3, 2, 6, 95],\n",
              " [3, 2, 6, 95, 96],\n",
              " [3, 2, 6, 95, 96, 5],\n",
              " [3, 2, 6, 95, 96, 5, 4],\n",
              " [3, 2, 6, 95, 96, 5, 4, 2],\n",
              " [3, 2, 6, 95, 96, 5, 4, 2, 13],\n",
              " [3, 2, 6, 95, 96, 5, 4, 2, 13, 26],\n",
              " [3, 2, 6, 95, 96, 5, 4, 2, 13, 26, 8],\n",
              " [3, 2, 6, 95, 96, 5, 4, 2, 13, 26, 8, 15],\n",
              " [3, 2, 6, 95, 96, 5, 4, 2, 13, 26, 8, 15, 44],\n",
              " [7, 1],\n",
              " [7, 1, 30],\n",
              " [7, 1, 30, 22],\n",
              " [7, 1, 30, 22, 225],\n",
              " [7, 1, 30, 22, 225, 97],\n",
              " [7, 1, 30, 22, 225, 97, 5],\n",
              " [7, 1, 30, 22, 225, 97, 5, 226],\n",
              " [7, 1, 30, 22, 225, 97, 5, 226, 97],\n",
              " [7, 1, 30, 22, 225, 97, 5, 226, 97, 8],\n",
              " [7, 1, 30, 22, 225, 97, 5, 226, 97, 8, 1],\n",
              " [7, 1, 30, 22, 225, 97, 5, 226, 97, 8, 1, 60],\n",
              " [7, 1, 30, 22, 225, 97, 5, 226, 97, 8, 1, 60, 10],\n",
              " [7, 1, 30, 22, 225, 97, 5, 226, 97, 8, 1, 60, 10, 6],\n",
              " [7, 1, 30, 22, 225, 97, 5, 226, 97, 8, 1, 60, 10, 6, 95],\n",
              " [7, 1, 30, 22, 225, 97, 5, 226, 97, 8, 1, 60, 10, 6, 95, 96],\n",
              " [54, 227],\n",
              " [54, 227, 228],\n",
              " [54, 227, 228, 229],\n",
              " [54, 227, 228, 229, 57],\n",
              " [54, 227, 228, 229, 57, 5],\n",
              " [54, 227, 228, 229, 57, 5, 98],\n",
              " [54, 227, 228, 229, 57, 5, 98, 230],\n",
              " [54, 227, 228, 229, 57, 5, 98, 230, 98],\n",
              " [54, 227, 228, 229, 57, 5, 98, 230, 98, 231],\n",
              " [54, 227, 228, 229, 57, 5, 98, 230, 98, 231, 84],\n",
              " [54, 227, 228, 229, 57, 5, 98, 230, 98, 231, 84, 232],\n",
              " [54, 227, 228, 229, 57, 5, 98, 230, 98, 231, 84, 232, 233],\n",
              " [99, 25],\n",
              " [99, 25, 9],\n",
              " [99, 25, 9, 100],\n",
              " [99, 25, 9, 100, 69],\n",
              " [99, 25, 9, 100, 69, 234],\n",
              " [99, 25, 9, 100, 69, 234, 1],\n",
              " [99, 25, 9, 100, 69, 234, 1, 235],\n",
              " [99, 25, 9, 100, 69, 234, 1, 235, 31],\n",
              " [99, 25, 9, 100, 69, 234, 1, 235, 31, 58],\n",
              " [99, 25, 9, 100, 69, 234, 1, 235, 31, 58, 92],\n",
              " [3, 20],\n",
              " [3, 20, 1],\n",
              " [3, 20, 1, 236],\n",
              " [3, 20, 1, 236, 237],\n",
              " [3, 20, 1, 236, 237, 8],\n",
              " [3, 20, 1, 236, 237, 8, 238],\n",
              " [3, 20, 1, 236, 237, 8, 238, 239],\n",
              " [3, 20, 1, 236, 237, 8, 238, 239, 15],\n",
              " [4, 29],\n",
              " [4, 29, 240],\n",
              " [4, 29, 240, 43],\n",
              " [4, 29, 240, 43, 241],\n",
              " [4, 29, 240, 43, 241, 242],\n",
              " [4, 29, 240, 43, 241, 242, 6],\n",
              " [4, 29, 240, 43, 241, 242, 6, 16],\n",
              " [4, 29, 240, 43, 241, 242, 6, 16, 11],\n",
              " [4, 29, 240, 43, 241, 242, 6, 16, 11, 19],\n",
              " [4, 29, 240, 43, 241, 242, 6, 16, 11, 19, 5],\n",
              " [4, 29, 240, 43, 241, 242, 6, 16, 11, 19, 5, 4],\n",
              " [4, 29, 240, 43, 241, 242, 6, 16, 11, 19, 5, 4, 25],\n",
              " [4, 29, 240, 43, 241, 242, 6, 16, 11, 19, 5, 4, 25, 9],\n",
              " [4, 29, 240, 43, 241, 242, 6, 16, 11, 19, 5, 4, 25, 9, 101],\n",
              " [4, 29, 240, 43, 241, 242, 6, 16, 11, 19, 5, 4, 25, 9, 101, 243],\n",
              " [7, 1],\n",
              " [7, 1, 61],\n",
              " [7, 1, 61, 244],\n",
              " [7, 1, 61, 244, 10],\n",
              " [7, 1, 61, 244, 10, 6],\n",
              " [7, 1, 61, 244, 10, 6, 102],\n",
              " [7, 1, 61, 244, 10, 6, 102, 11],\n",
              " [7, 1, 61, 244, 10, 6, 102, 11, 245],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 30],\n",
              " [3, 2, 1, 30, 22],\n",
              " [3, 2, 1, 30, 22, 47],\n",
              " [3, 2, 1, 30, 22, 47, 11],\n",
              " [3, 2, 1, 30, 22, 47, 11, 5],\n",
              " [3, 2, 1, 30, 22, 47, 11, 5, 102],\n",
              " [3, 2, 1, 30, 22, 47, 11, 5, 102, 11],\n",
              " [17, 2],\n",
              " [17, 2, 246],\n",
              " [17, 2, 246, 45],\n",
              " [17, 2, 246, 45, 24],\n",
              " [17, 2, 246, 45, 24, 8],\n",
              " [17, 2, 246, 45, 24, 8, 18],\n",
              " [17, 2, 246, 45, 24, 8, 18, 21],\n",
              " [7, 1],\n",
              " [7, 1, 30],\n",
              " [7, 1, 30, 22],\n",
              " [7, 1, 30, 22, 247],\n",
              " [7, 1, 30, 22, 247, 45],\n",
              " [7, 1, 30, 22, 247, 45, 82],\n",
              " [7, 1, 30, 22, 247, 45, 82, 45],\n",
              " [7, 1, 30, 22, 247, 45, 82, 45, 5],\n",
              " [7, 1, 30, 22, 247, 45, 82, 45, 5, 248],\n",
              " [7, 1, 30, 22, 247, 45, 82, 45, 5, 248, 45],\n",
              " [4, 12],\n",
              " [4, 12, 103],\n",
              " [4, 12, 103, 90],\n",
              " [4, 12, 103, 90, 16],\n",
              " [4, 12, 103, 90, 16, 11],\n",
              " [4, 12, 103, 90, 16, 11, 56],\n",
              " [3, 249],\n",
              " [3, 249, 29],\n",
              " [3, 249, 29, 43],\n",
              " [3, 249, 29, 43, 26],\n",
              " [3, 249, 29, 43, 26, 28],\n",
              " [3, 249, 29, 43, 26, 28, 104],\n",
              " [3, 249, 29, 43, 26, 28, 104, 5],\n",
              " [3, 249, 29, 43, 26, 28, 104, 5, 14],\n",
              " [3, 249, 29, 43, 26, 28, 104, 5, 14, 103],\n",
              " [7, 1],\n",
              " [7, 1, 105],\n",
              " [7, 1, 105, 33],\n",
              " [7, 1, 105, 33, 34],\n",
              " [4, 23],\n",
              " [4, 23, 105],\n",
              " [4, 23, 105, 33],\n",
              " [4, 23, 105, 33, 14],\n",
              " [4, 23, 105, 33, 14, 250],\n",
              " [4, 23, 105, 33, 14, 250, 106],\n",
              " [4, 23, 105, 33, 14, 250, 106, 251],\n",
              " [3, 2],\n",
              " [3, 2, 107],\n",
              " [3, 2, 107, 5],\n",
              " [3, 2, 107, 5, 17],\n",
              " [3, 2, 107, 5, 17, 2],\n",
              " [3, 2, 107, 5, 17, 2, 13],\n",
              " [3, 2, 107, 5, 17, 2, 13, 6],\n",
              " [3, 2, 107, 5, 17, 2, 13, 6, 36],\n",
              " [3, 2, 107, 5, 17, 2, 13, 6, 36, 8],\n",
              " [3, 2, 107, 5, 17, 2, 13, 6, 36, 8, 50],\n",
              " [3, 2, 107, 5, 17, 2, 13, 6, 36, 8, 50, 33],\n",
              " [4, 29],\n",
              " [4, 29, 9],\n",
              " [4, 29, 9, 104],\n",
              " [4, 29, 9, 104, 5],\n",
              " [4, 29, 9, 104, 5, 101],\n",
              " [4, 29, 9, 104, 5, 101, 107],\n",
              " [4, 29, 9, 104, 5, 101, 107, 8],\n",
              " [4, 29, 9, 104, 5, 101, 107, 8, 6],\n",
              " [4, 29, 9, 104, 5, 101, 107, 8, 6, 32],\n",
              " [252, 253],\n",
              " [252, 253, 254],\n",
              " [252, 253, 254, 255],\n",
              " [17, 20],\n",
              " [17, 20, 9],\n",
              " [17, 20, 9, 256],\n",
              " [17, 20, 9, 256, 8],\n",
              " [17, 20, 9, 256, 8, 1],\n",
              " [17, 20, 9, 256, 8, 1, 108],\n",
              " [17, 20, 9, 256, 8, 1, 108, 10],\n",
              " [17, 20, 9, 256, 8, 1, 108, 10, 16],\n",
              " [17, 20, 9, 256, 8, 1, 108, 10, 16, 11],\n",
              " [17, 20, 9, 256, 8, 1, 108, 10, 16, 11, 15],\n",
              " [17, 20, 9, 256, 8, 1, 108, 10, 16, 11, 15, 44],\n",
              " [3, 46],\n",
              " [3, 46, 257],\n",
              " [3, 46, 257, 9],\n",
              " [3, 46, 257, 9, 258],\n",
              " [3, 46, 257, 9, 258, 259],\n",
              " [3, 46, 257, 9, 258, 259, 260],\n",
              " [3, 46, 257, 9, 258, 259, 260, 62],\n",
              " [3, 46, 257, 9, 258, 259, 260, 62, 109],\n",
              " [3, 46, 257, 9, 258, 259, 260, 62, 109, 38],\n",
              " [3, 46, 257, 9, 258, 259, 260, 62, 109, 38, 261],\n",
              " [3, 46, 257, 9, 258, 259, 260, 62, 109, 38, 261, 46],\n",
              " [3, 262],\n",
              " [3, 262, 263],\n",
              " [3, 262, 263, 20],\n",
              " [3, 262, 263, 20, 9],\n",
              " [3, 262, 263, 20, 9, 264],\n",
              " [3, 262, 263, 20, 9, 264, 42],\n",
              " [7, 1],\n",
              " [7, 1, 30],\n",
              " [7, 1, 30, 22],\n",
              " [7, 1, 30, 22, 47],\n",
              " [7, 1, 30, 22, 47, 5],\n",
              " [7, 1, 30, 22, 47, 5, 63],\n",
              " [7, 1, 30, 22, 47, 5, 63, 11],\n",
              " [3, 2],\n",
              " [3, 2, 64],\n",
              " [3, 2, 64, 65],\n",
              " [3, 2, 64, 65, 5],\n",
              " [3, 2, 64, 65, 5, 17],\n",
              " [3, 2, 64, 65, 5, 17, 2],\n",
              " [3, 2, 64, 65, 5, 17, 2, 13],\n",
              " [3, 2, 64, 65, 5, 17, 2, 13, 24],\n",
              " [110, 6],\n",
              " [110, 6, 16],\n",
              " [110, 6, 16, 11],\n",
              " [110, 6, 16, 11, 19],\n",
              " [110, 6, 16, 11, 19, 265],\n",
              " [110, 6, 16, 11, 19, 265, 266],\n",
              " [3, 2],\n",
              " [3, 2, 66],\n",
              " [3, 2, 66, 5],\n",
              " [3, 2, 66, 5, 4],\n",
              " [3, 2, 66, 5, 4, 29],\n",
              " [3, 2, 66, 5, 4, 29, 13],\n",
              " [3, 2, 66, 5, 4, 29, 13, 43],\n",
              " [3, 2, 66, 5, 4, 29, 13, 43, 267],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 39],\n",
              " [3, 2, 1, 39, 48],\n",
              " [3, 2, 1, 39, 48, 49],\n",
              " [4, 12],\n",
              " [4, 12, 9],\n",
              " [4, 12, 9, 14],\n",
              " [4, 12, 9, 14, 79],\n",
              " [4, 12, 9, 14, 79, 15],\n",
              " [4, 12, 9, 14, 79, 15, 8],\n",
              " [4, 12, 9, 14, 79, 15, 8, 6],\n",
              " [4, 12, 9, 14, 79, 15, 8, 6, 32],\n",
              " [7, 1],\n",
              " [7, 1, 27],\n",
              " [7, 1, 27, 10],\n",
              " [7, 1, 27, 10, 41],\n",
              " [7, 1, 27, 10, 41, 5],\n",
              " [7, 1, 27, 10, 41, 5, 17],\n",
              " [7, 1, 27, 10, 41, 5, 17, 13],\n",
              " [7, 1, 27, 10, 41, 5, 17, 13, 2],\n",
              " [7, 1, 27, 10, 41, 5, 17, 13, 2, 24],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 30],\n",
              " [3, 2, 1, 30, 22],\n",
              " [3, 2, 1, 30, 22, 6],\n",
              " [3, 2, 1, 30, 22, 6, 268],\n",
              " [3, 2, 1, 30, 22, 6, 268, 5],\n",
              " [3, 2, 1, 30, 22, 6, 268, 5, 6],\n",
              " [3, 2, 1, 30, 22, 6, 268, 5, 6, 269],\n",
              " [3, 2, 1, 30, 22, 6, 268, 5, 6, 269, 8],\n",
              " [3, 2, 1, 30, 22, 6, 268, 5, 6, 269, 8, 270],\n",
              " [4, 25],\n",
              " [4, 25, 9],\n",
              " [4, 25, 9, 271],\n",
              " [4, 25, 9, 271, 5],\n",
              " [4, 25, 9, 271, 5, 272],\n",
              " [4, 25, 9, 271, 5, 272, 6],\n",
              " [4, 25, 9, 271, 5, 272, 6, 32],\n",
              " [4, 25, 9, 271, 5, 272, 6, 32, 273],\n",
              " [4, 25, 9, 271, 5, 272, 6, 32, 273, 76],\n",
              " [4, 25, 9, 271, 5, 272, 6, 32, 273, 76, 13],\n",
              " [4, 25, 9, 271, 5, 272, 6, 32, 273, 76, 13, 8],\n",
              " [4, 25, 9, 271, 5, 272, 6, 32, 273, 76, 13, 8, 6],\n",
              " [4, 25, 9, 271, 5, 272, 6, 32, 273, 76, 13, 8, 6, 16],\n",
              " [4, 25, 9, 271, 5, 272, 6, 32, 273, 76, 13, 8, 6, 16, 11],\n",
              " [4, 25, 9, 271, 5, 272, 6, 32, 273, 76, 13, 8, 6, 16, 11, 19],\n",
              " [3, 2],\n",
              " [3, 2, 1],\n",
              " [3, 2, 1, 61],\n",
              " [3, 2, 1, 61, 274],\n",
              " [3, 2, 1, 61, 274, 10],\n",
              " [3, 2, 1, 61, 274, 10, 6],\n",
              " [3, 2, 1, 61, 274, 10, 6, 18],\n",
              " [3, 2, 1, 61, 274, 10, 6, 18, 70],\n",
              " [7, 1],\n",
              " [7, 1, 67],\n",
              " [7, 1, 67, 10],\n",
              " [7, 1, 67, 10, 71],\n",
              " [7, 1, 67, 10, 71, 72],\n",
              " [7, 1, 67, 10, 71, 72, 8],\n",
              " [7, 1, 67, 10, 71, 72, 8, 18],\n",
              " [7, 1, 67, 10, 71, 72, 8, 18, 21],\n",
              " [3, 2],\n",
              " [3, 2, 275],\n",
              " [3, 2, 275, 8],\n",
              " [3, 2, 275, 8, 1],\n",
              " [3, 2, 275, 8, 1, 60],\n",
              " [3, 2, 275, 8, 1, 60, 10],\n",
              " [3, 2, 275, 8, 1, 60, 10, 18],\n",
              " [3, 2, 275, 8, 1, 60, 10, 18, 21],\n",
              " [4, 12],\n",
              " [4, 12, 276],\n",
              " [4, 12, 276, 18],\n",
              " [4, 12, 276, 18, 21],\n",
              " [4, 12, 276, 18, 21, 73],\n",
              " [4, 12, 276, 18, 21, 73, 88],\n",
              " [4, 12, 276, 18, 21, 73, 88, 37],\n",
              " [4, 12, 276, 18, 21, 73, 88, 37, 277],\n",
              " [4, 12, 276, 18, 21, 73, 88, 37, 277, 18],\n",
              " [4, 12, 276, 18, 21, 73, 88, 37, 277, 18, 21],\n",
              " [111, 6],\n",
              " [111, 6, 32],\n",
              " [111, 6, 32, 4],\n",
              " [111, 6, 32, 4, 25],\n",
              " [111, 6, 32, 4, 25, 9],\n",
              " [111, 6, 32, 4, 25, 9, 278],\n",
              " [111, 6, 32, 4, 25, 9, 278, 279],\n",
              " [111, 6, 32, 4, 25, 9, 278, 279, 5],\n",
              " [111, 6, 32, 4, 25, 9, 278, 279, 5, 280],\n",
              " [111, 6, 32, 4, 25, 9, 278, 279, 5, 280, 13],\n",
              " [281, 9],\n",
              " [281, 9, 282],\n",
              " [281, 9, 282, 6],\n",
              " [281, 9, 282, 6, 32],\n",
              " [281, 9, 282, 6, 32, 42],\n",
              " [281, 9, 282, 6, 32, 42, 6],\n",
              " [281, 9, 282, 6, 32, 42, 6, 106],\n",
              " [281, 9, 282, 6, 32, 42, 6, 106, 283],\n",
              " [281, 9, 282, 6, 32, 42, 6, 106, 283, 4],\n",
              " [281, 9, 282, 6, 32, 42, 6, 106, 283, 4, 25],\n",
              " [281, 9, 282, 6, 32, 42, 6, 106, 283, 4, 25, 9],\n",
              " [281, 9, 282, 6, 32, 42, 6, 106, 283, 4, 25, 9, 14],\n",
              " [281, 9, 282, 6, 32, 42, 6, 106, 283, 4, 25, 9, 14, 13],\n",
              " [4, 25],\n",
              " [4, 25, 9],\n",
              " [4, 25, 9, 100],\n",
              " [4, 25, 9, 100, 22],\n",
              " [4, 25, 9, 100, 22, 284],\n",
              " [4, 25, 9, 100, 22, 284, 16],\n",
              " [4, 25, 9, 100, 22, 284, 16, 11],\n",
              " [4, 25, 9, 100, 22, 284, 16, 11, 56],\n",
              " [4, 25, 9, 100, 22, 284, 16, 11, 56, 31],\n",
              " [4, 25, 9, 100, 22, 284, 16, 11, 56, 31, 6],\n",
              " [4, 25, 9, 100, 22, 284, 16, 11, 56, 31, 6, 285],\n",
              " [4, 25, 9, 100, 22, 284, 16, 11, 56, 31, 6, 285, 286],\n",
              " [7, 6],\n",
              " [7, 6, 93],\n",
              " [7, 6, 93, 27],\n",
              " [7, 6, 93, 27, 37],\n",
              " [7, 6, 93, 27, 37, 62],\n",
              " [7, 6, 93, 27, 37, 62, 109],\n",
              " [7, 6, 93, 27, 37, 62, 109, 38],\n",
              " [7, 6, 93, 27, 37, 62, 109, 38, 46],\n",
              " [7, 6, 93, 27, 37, 62, 109, 38, 46, 8],\n",
              " [7, 6, 93, 27, 37, 62, 109, 38, 46, 8, 6],\n",
              " [7, 6, 93, 27, 37, 62, 109, 38, 46, 8, 6, 287],\n",
              " [7, 6, 93, 27, 37, 62, 109, 38, 46, 8, 6, 287, 288],\n",
              " [4, 12],\n",
              " [4, 12, 9],\n",
              " [4, 12, 9, 14],\n",
              " [4, 12, 9, 14, 289],\n",
              " [4, 12, 9, 14, 289, 290],\n",
              " [4, 12, 9, 14, 289, 290, 5],\n",
              " [4, 12, 9, 14, 289, 290, 5, 291],\n",
              " [4, 12, 9, 14, 289, 290, 5, 291, 46],\n",
              " [110, 6],\n",
              " [110, 6, 292],\n",
              " [110, 6, 292, 36],\n",
              " [110, 6, 292, 36, 9],\n",
              " [110, 6, 292, 36, 9, 293],\n",
              " [110, 6, 292, 36, 9, 293, 8],\n",
              " [110, 6, 292, 36, 9, 293, 8, 6],\n",
              " [110, 6, 292, 36, 9, 293, 8, 6, 112],\n",
              " [110, 6, 292, 36, 9, 293, 8, 6, 112, 5],\n",
              " [110, 6, 292, 36, 9, 293, 8, 6, 112, 5, 4],\n",
              " [110, 6, 292, 36, 9, 293, 8, 6, 112, 5, 4, 9],\n",
              " [110, 6, 292, 36, 9, 293, 8, 6, 112, 5, 4, 9, 294],\n",
              " [110, 6, 292, 36, 9, 293, 8, 6, 112, 5, 4, 9, 294, 13],\n",
              " [4, 12],\n",
              " [4, 12, 9],\n",
              " [4, 12, 9, 295],\n",
              " [4, 12, 9, 295, 296],\n",
              " [4, 12, 9, 295, 296, 42],\n",
              " [4, 12, 9, 295, 296, 42, 1],\n",
              " [4, 12, 9, 295, 296, 42, 1, 297],\n",
              " [4, 12, 9, 295, 296, 42, 1, 297, 298],\n",
              " [4, 12, 9, 295, 296, 42, 1, 297, 298, 8],\n",
              " [4, 12, 9, 295, 296, 42, 1, 297, 298, 8, 16],\n",
              " [4, 12, 9, 295, 296, 42, 1, 297, 298, 8, 16, 11],\n",
              " [4, 12, 9, 295, 296, 42, 1, 297, 298, 8, 16, 11, 5],\n",
              " [4, 12, 9, 295, 296, 42, 1, 297, 298, 8, 16, 11, 5, 15],\n",
              " [4, 12, 9, 295, 296, 42, 1, 297, 298, 8, 16, 11, 5, 15, 44],\n",
              " [4, 12],\n",
              " [4, 12, 9],\n",
              " [4, 12, 9, 14],\n",
              " [4, 12, 9, 14, 299],\n",
              " [4, 12, 9, 14, 299, 99],\n",
              " [4, 12, 9, 14, 299, 99, 62],\n",
              " [4, 12, 9, 14, 299, 99, 62, 113],\n",
              " [4, 12, 9, 14, 299, 99, 62, 113, 38],\n",
              " [4, 12, 9, 14, 299, 99, 62, 113, 38, 19],\n",
              " [4, 12, 9, 14, 299, 99, 62, 113, 38, 19, 300],\n",
              " [4, 12, 9, 14, 299, 99, 62, 113, 38, 19, 300, 114],\n",
              " [4, 12, 9, 14, 299, 99, 62, 113, 38, 19, 300, 114, 301],\n",
              " [4, 12, 9, 14, 299, 99, 62, 113, 38, 19, 300, 114, 301, 302],\n",
              " [17, 12],\n",
              " [17, 12, 9],\n",
              " [17, 12, 9, 303],\n",
              " [17, 12, 9, 303, 28],\n",
              " [17, 12, 9, 303, 28, 114],\n",
              " [17, 12, 9, 303, 28, 114, 31],\n",
              " [17, 12, 9, 303, 28, 114, 31, 304],\n",
              " [17, 12, 9, 303, 28, 114, 31, 304, 305],\n",
              " [3, 306],\n",
              " [3, 306, 307],\n",
              " [3, 306, 307, 38],\n",
              " [3, 306, 307, 38, 308],\n",
              " [3, 306, 307, 38, 308, 8],\n",
              " [3, 306, 307, 38, 308, 8, 16],\n",
              " [3, 306, 307, 38, 308, 8, 16, 11],\n",
              " [3, 306, 307, 38, 308, 8, 16, 11, 15],\n",
              " [3, 306, 307, 38, 308, 8, 16, 11, 15, 44],\n",
              " [3, 306, 307, 38, 308, 8, 16, 11, 15, 44, 309],\n",
              " [3, 306, 307, 38, 308, 8, 16, 11, 15, 44, 309, 9],\n",
              " [3, 306, 307, 38, 308, 8, 16, 11, 15, 44, 309, 9, 1],\n",
              " [3, 306, 307, 38, 308, 8, 16, 11, 15, 44, 309, 9, 1, 310],\n",
              " [29, 9],\n",
              " [29, 9, 311],\n",
              " [29, 9, 311, 312],\n",
              " [29, 9, 311, 312, 313],\n",
              " [29, 9, 311, 312, 313, 314],\n",
              " [29, 9, 311, 312, 313, 314, 38],\n",
              " [29, 9, 311, 312, 313, 314, 38, 315],\n",
              " [29, 9, 311, 312, 313, 314, 38, 315, 316],\n",
              " [29, 9, 311, 312, 313, 314, 38, 315, 316, 317],\n",
              " [29, 9, 311, 312, 313, 314, 38, 315, 316, 317, 8],\n",
              " [29, 9, 311, 312, 313, 314, 38, 315, 316, 317, 8, 1],\n",
              " [29, 9, 311, 312, 313, 314, 38, 315, 316, 317, 8, 1, 108],\n",
              " [81, 113],\n",
              " [81, 113, 28],\n",
              " [81, 113, 28, 318],\n",
              " [81, 113, 28, 318, 50],\n",
              " [81, 113, 28, 318, 50, 33],\n",
              " [81, 113, 28, 318, 50, 33, 37],\n",
              " [81, 113, 28, 318, 50, 33, 37, 319],\n",
              " [7, 1],\n",
              " [7, 1, 89],\n",
              " [7, 1, 89, 10],\n",
              " [7, 1, 89, 10, 6],\n",
              " [7, 1, 89, 10, 6, 16],\n",
              " [7, 1, 89, 10, 6, 16, 11],\n",
              " [7, 1, 89, 10, 6, 16, 11, 112],\n",
              " [7, 1, 89, 10, 6, 16, 11, 112, 37],\n",
              " [7, 1, 89, 10, 6, 16, 11, 112, 37, 36],\n",
              " [7, 1, 89, 10, 6, 16, 11, 112, 37, 36, 320],\n",
              " [7, 1, 89, 10, 6, 16, 11, 112, 37, 36, 320, 28],\n",
              " [7, 1, 89, 10, 6, 16, 11, 112, 37, 36, 320, 28, 80],\n",
              " [111, 6],\n",
              " [111, 6, 32],\n",
              " [111, 6, 32, 321],\n",
              " [111, 6, 32, 321, 77],\n",
              " [111, 6, 32, 321, 77, 15],\n",
              " [111, 6, 32, 321, 77, 15, 57],\n",
              " [111, 6, 32, 321, 77, 15, 57, 5],\n",
              " [111, 6, 32, 321, 77, 15, 57, 5, 322],\n",
              " [111, 6, 32, 321, 77, 15, 57, 5, 322, 24],\n",
              " [111, 6, 32, 321, 77, 15, 57, 5, 322, 24, 323]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "uj73cPC8-S_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding = 'pre')"
      ],
      "metadata": {
        "id": "1g8kLX0z_DMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmHCu5tC_4D1",
        "outputId": "c10fffe8-1df5-47df-e9cc-629a4bff0db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   3,   2],\n",
              "       [  0,   0,   0, ...,   3,   2,   1],\n",
              "       [  0,   0,   0, ...,   2,   1,  30],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  57,   5, 322],\n",
              "       [  0,   0,   0, ...,   5, 322,  24],\n",
              "       [  0,   0,   0, ..., 322,  24, 323]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting 1st column to second last column into input\n",
        "X = padded_input_sequences[:,:-1]\n",
        "#converting last column into output\n",
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "-bcLGmrG_5j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCItomz1QpYF",
        "outputId": "4ff62443-c3a7-4c55-83da-dae033885191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(867, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djeqBCd7PW_V",
        "outputId": "3654935f-6c59-4291-aa59-f4c54dc7e39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(867,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=324) #doing one hot encoding"
      ],
      "metadata": {
        "id": "VAaPAVvYBVrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "ntLM_3BtCtZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Reshape"
      ],
      "metadata": {
        "id": "EZ60Ws2TCi7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(324, 100, input_length = 15))\n",
        "model.add(GRU(150,return_sequences = True))\n",
        "model.add(Reshape((15, 150)))\n",
        "model.add(GRU(150))\n",
        "model.add(Dense(324, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "Mdw10efsDDFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "zLGL-gDrDydr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6geIiYEpEDKs",
        "outputId": "b65da34a-e497-4044-9982-ea7850aae5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 15, 100)           32400     \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 15, 150)           113400    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 15, 150)           0         \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 150)               135900    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 324)               48924     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330624 (1.26 MB)\n",
            "Trainable params: 330624 (1.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9MYKN4OFa_y",
        "outputId": "0b00c603-b91d-4c67-bedd-cb6e1f120a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "28/28 [==============================] - 10s 87ms/step - loss: 5.5061 - accuracy: 0.0554\n",
            "Epoch 2/50\n",
            "28/28 [==============================] - 2s 84ms/step - loss: 5.0673 - accuracy: 0.0611\n",
            "Epoch 3/50\n",
            "28/28 [==============================] - 2s 78ms/step - loss: 4.9433 - accuracy: 0.0715\n",
            "Epoch 4/50\n",
            "28/28 [==============================] - 3s 112ms/step - loss: 4.7844 - accuracy: 0.1188\n",
            "Epoch 5/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 4.5454 - accuracy: 0.1442\n",
            "Epoch 6/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 4.2705 - accuracy: 0.1719\n",
            "Epoch 7/50\n",
            "28/28 [==============================] - 2s 56ms/step - loss: 4.0045 - accuracy: 0.2168\n",
            "Epoch 8/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 3.7217 - accuracy: 0.2572\n",
            "Epoch 9/50\n",
            "28/28 [==============================] - 2s 57ms/step - loss: 3.4615 - accuracy: 0.2872\n",
            "Epoch 10/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 3.2160 - accuracy: 0.3310\n",
            "Epoch 11/50\n",
            "28/28 [==============================] - 2s 86ms/step - loss: 2.9907 - accuracy: 0.3599\n",
            "Epoch 12/50\n",
            "28/28 [==============================] - 2s 68ms/step - loss: 2.7949 - accuracy: 0.3668\n",
            "Epoch 13/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 2.5902 - accuracy: 0.4152\n",
            "Epoch 14/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 2.4092 - accuracy: 0.4464\n",
            "Epoch 15/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 2.2609 - accuracy: 0.4648\n",
            "Epoch 16/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 2.1138 - accuracy: 0.5052\n",
            "Epoch 17/50\n",
            "28/28 [==============================] - 2s 74ms/step - loss: 1.9553 - accuracy: 0.5340\n",
            "Epoch 18/50\n",
            "28/28 [==============================] - 2s 85ms/step - loss: 1.8286 - accuracy: 0.5617\n",
            "Epoch 19/50\n",
            "28/28 [==============================] - 3s 108ms/step - loss: 1.7094 - accuracy: 0.6217\n",
            "Epoch 20/50\n",
            "28/28 [==============================] - 2s 59ms/step - loss: 1.5825 - accuracy: 0.6309\n",
            "Epoch 21/50\n",
            "28/28 [==============================] - 2s 57ms/step - loss: 1.4770 - accuracy: 0.6851\n",
            "Epoch 22/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 1.3705 - accuracy: 0.6955\n",
            "Epoch 23/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 1.3049 - accuracy: 0.7186\n",
            "Epoch 24/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 1.2279 - accuracy: 0.7405\n",
            "Epoch 25/50\n",
            "28/28 [==============================] - 2s 89ms/step - loss: 1.1509 - accuracy: 0.7532\n",
            "Epoch 26/50\n",
            "28/28 [==============================] - 2s 66ms/step - loss: 1.0822 - accuracy: 0.7682\n",
            "Epoch 27/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 1.0168 - accuracy: 0.7762\n",
            "Epoch 28/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 0.9716 - accuracy: 0.7843\n",
            "Epoch 29/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 0.9262 - accuracy: 0.7993\n",
            "Epoch 30/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 0.8879 - accuracy: 0.8039\n",
            "Epoch 31/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 0.8767 - accuracy: 0.8039\n",
            "Epoch 32/50\n",
            "28/28 [==============================] - 2s 71ms/step - loss: 0.8302 - accuracy: 0.8062\n",
            "Epoch 33/50\n",
            "28/28 [==============================] - 2s 80ms/step - loss: 0.7766 - accuracy: 0.8270\n",
            "Epoch 34/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 0.7671 - accuracy: 0.8155\n",
            "Epoch 35/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 0.7281 - accuracy: 0.8304\n",
            "Epoch 36/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 0.7064 - accuracy: 0.8316\n",
            "Epoch 37/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 0.6853 - accuracy: 0.8270\n",
            "Epoch 38/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 0.6781 - accuracy: 0.8316\n",
            "Epoch 39/50\n",
            "28/28 [==============================] - 2s 56ms/step - loss: 0.6528 - accuracy: 0.8339\n",
            "Epoch 40/50\n",
            "28/28 [==============================] - 3s 102ms/step - loss: 0.6415 - accuracy: 0.8385\n",
            "Epoch 41/50\n",
            "28/28 [==============================] - 2s 63ms/step - loss: 0.6268 - accuracy: 0.8397\n",
            "Epoch 42/50\n",
            "28/28 [==============================] - 2s 56ms/step - loss: 0.6211 - accuracy: 0.8385\n",
            "Epoch 43/50\n",
            "28/28 [==============================] - 2s 56ms/step - loss: 0.6060 - accuracy: 0.8408\n",
            "Epoch 44/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 0.5930 - accuracy: 0.8443\n",
            "Epoch 45/50\n",
            "28/28 [==============================] - 2s 56ms/step - loss: 0.5748 - accuracy: 0.8420\n",
            "Epoch 46/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 0.5798 - accuracy: 0.8408\n",
            "Epoch 47/50\n",
            "28/28 [==============================] - 3s 98ms/step - loss: 0.5700 - accuracy: 0.8374\n",
            "Epoch 48/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 0.5565 - accuracy: 0.8443\n",
            "Epoch 49/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 0.5516 - accuracy: 0.8489\n",
            "Epoch 50/50\n",
            "28/28 [==============================] - 2s 56ms/step - loss: 0.5413 - accuracy: 0.8431\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7919198a7520>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"what is\"\n",
        "\n",
        "for i in range(10):\n",
        "  #tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  #padding\n",
        "  padded_token_text = pad_sequences([token_text],maxlen = 15, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRP2lk_9H2da",
        "outputId": "5ab5a5c7-06f7-47b7-d81a-9176965c16f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "what is the\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "what is the difference\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "what is the difference between\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "what is the difference between supervised\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "what is the difference between supervised and\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "what is the difference between supervised and unsupervised\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "what is the difference between supervised and unsupervised learning\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "what is the difference between supervised and unsupervised learning system\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "what is the difference between supervised and unsupervised learning system science\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "what is the difference between supervised and unsupervised learning system science interest\n"
          ]
        }
      ]
    }
  ]
}